from collections import OrderedDict

import pandas as pd
from django_hosts import reverse
from pandas import DataFrame, Series, merge
from waffle import flag_is_active

from config.hosts import PUBLISH_HOST
from transit_odp.common.collections import Column
from transit_odp.fares.models import DataCatalogueMetaData
from transit_odp.organisation.csv import EmptyDataFrame
from transit_odp.organisation.models import Dataset, TXCFileAttributes

FEATURE_FLAG_OVERALL_COLUMN_MAP = OrderedDict(
    {
        "organisation_name": Column(
            "Operator", "The name of the operator/publisher providing data on BODS."
        ),
        "organisation_id": Column(
            "Operator ID",
            "The internal BODS generated ID of the operator/publisher providing"
            " data on BODS.",
        ),
        "profile_nocs": Column(
            "Profile NOCs",
            (
                "The National Operator Codes for the particular publisher as extracted "
                "from their BODS profile."
            ),
        ),
        "dataset_type_pretty": Column("Data Type", "The type of data being published."),
        "status": Column("Status", "The publication status of the data set/feed."),
        "last_updated": Column(
            "Last Updated", "The date that the data set/feed was last updated on BODS."
        ),
        "upload_filename": Column(
            "File Name",
            "The exact name of the file provided to BODS. This is usually generated by "
            "the publisher or their supplier",
        ),
        "filename": Column(
            "XML File Name",
            "The value of the FileName attribute in the TransXChange or NeTEx file.",
        ),
        "name": Column(
            "Data Set/Feed Name",
            "The internal BODS generated data set name given for a particular"
            " data set.",
        ),
        "id": Column(
            "Data ID",
            "The internal BODS generated ID of the data set / feed provided to BODS.",
        ),
        "mode": Column(
            "Mode",
            "The mode of transport as extracted from the TransXChange "
            "file they provided.",
        ),
        "national_operator_code": Column(
            "National Operator Code",
            "The National Operator Code(s) for the particular publisher as extracted "
            "from the TransXChange or NeTEx file they provided.",
        ),
        "service_code": Column(
            "Service Code",
            "The ServiceCode for the particular publisher as extracted from "
            "the TransXChange file they provided.",
        ),
        "string_lines": Column(
            "Line Name",
            "The line name(s) for the particular publisher as extracted from "
            "the TransXChange or NeTEx file they provided.",
        ),
        "licence_number": Column(
            "Licence Number",
            "The License number(s) as extracted from the files provided by "
            "the operator/publisher to BODS.",
        ),
        "public_use": Column(
            "Public Use Flag",
            "The Public Use Flag element as extracted from the files provided "
            "by the operator/publisher to BODS.",
        ),
        "revision_number": Column(
            "Revision Number",
            "The service revision number date as extracted from the files "
            "provided by the operator/publisher to BODS.",
        ),
        "operating_period_start_date": Column(
            "Operating Period Start Date",
            "The operating period start date as extracted from the files provided "
            "by the operator/publisher to BODS.",
        ),
        "operating_period_end_date": Column(
            "Operating Period End Date",
            "The operating period end date as extracted from the files "
            "provided by the operator/publisher to BODS.",
        ),
        "avl_to_timtables_matching_score": Column(
            "% AVL to Timetables feed matching score",
            "The latest score for the active AVL feed this row belongs to (Data ID).",
        ),
        "matching_report_url": Column(
            "Latest matching report URL",
            (
                "This will be the same report url as the AVL data feed page "
                "report url from the dataset review page."
            ),
        ),
    }
)

OVERALL_COLUMN_MAP = OrderedDict(
    {
        "organisation_name": Column(
            "Operator", "The name of the operator/publisher providing data on BODS."
        ),
        "organisation_id": Column(
            "Operator ID",
            "The internal BODS generated ID of the operator/publisher providing"
            " data on BODS.",
        ),
        "profile_nocs": Column(
            "Profile NOCs",
            (
                "The National Operator Codes for the particular publisher as extracted "
                "from their BODS profile."
            ),
        ),
        "dataset_type_pretty": Column("Data Type", "The type of data being published."),
        "status": Column("Status", "The publication status of the data set/feed."),
        "last_updated": Column(
            "Last Updated", "The date that the data set/feed was last updated on BODS."
        ),
        "upload_filename": Column(
            "File Name",
            "The exact name of the file provided to BODS. This is usually generated by "
            "the publisher or their supplier",
        ),
        "filename": Column(
            "TXC File Name",
            "The value of the FileName attribute in the TransXChange file.",
        ),
        "name": Column(
            "Data Set/Feed Name",
            "The internal BODS generated data set name given for a particular"
            " data set.",
        ),
        "id": Column(
            "Data ID",
            "The internal BODS generated ID of the data set / feed provided to BODS.",
        ),
        "mode": Column(
            "Mode",
            "The mode of transport as extracted from the TransXChange "
            "file they provided.",
        ),
        "national_operator_code": Column(
            "National Operator Code",
            "The National Operator Codes for the particular publisher as extracted"
            " from the TransXChange file they provided.",
        ),
        "service_code": Column(
            "Service Code",
            "The ServiceCode for the particular publisher as extracted from "
            "the TransXChange file they provided.",
        ),
        "string_lines": Column(
            "Line Name",
            "The linename for the particular publisher as extracted from "
            "the TransXChange file they provided.",
        ),
    }
)

DATASET_FIELDS = (
    "organisation_name",
    "organisation_id",
    "profile_nocs",
    "dataset_type_pretty",
    "status",
    "last_updated",
    "upload_filename",
    "id",
    "name",
    "avl_to_timtables_matching_score",
)

TXC_FILE_ATTRIBUTE_FIELDS = (
    "dataset_id",
    "filename",
    "national_operator_code",
    "service_code",
    "string_lines",
    "licence_number",
    "public_use",
    "revision_number",
    "operating_period_start_date",
    "operating_period_end_date",
)

DATACATALOGUE_ATTRIBUTE_FIELDS = (
    "dataset_id",
    "fares_metadata_id",
    "xml_file_name",
    "string_nocs",
    "string_lines",
)


def get_matching_report_url(row: Series) -> str:
    if row["avl_to_timtables_matching_score"] is None or pd.isna(
        row["avl_to_timtables_matching_score"]
    ):
        return None
    if (
        row["dataset_type_pretty"] == "Automatic Vehicle Locations"
        and row["avl_to_timtables_matching_score"] is not None
    ):
        return reverse(
            "avl:download-matching-report",
            kwargs={"pk": row["id"], "pk1": row["organisation_id"]},
            host=PUBLISH_HOST,
        )


def _get_overall_catalogue_dataframe() -> DataFrame:
    is_fares_validator_active = flag_is_active("", "is_fares_validator_active")
    dataset_df = DataFrame.from_records(
        Dataset.objects.get_overall_data_catalogue_annotations().values(*DATASET_FIELDS)
    )

    txc_file_attributes_df = DataFrame.from_records(
        TXCFileAttributes.objects.get_overall_data_catalogue().values(
            *TXC_FILE_ATTRIBUTE_FIELDS
        )
    )

    if dataset_df.empty or txc_file_attributes_df.empty:
        raise EmptyDataFrame()

    if is_fares_validator_active:
        dataset_df["matching_report_url"] = dataset_df.apply(
            lambda x: get_matching_report_url(x), axis=1
        )

        dataset_df_fares = dataset_df[dataset_df["dataset_type_pretty"] == "Fares"]
        dataset_df = dataset_df[dataset_df["dataset_type_pretty"] != "Fares"]

        if dataset_df_fares.empty and dataset_df.empty:
            raise EmptyDataFrame()

        datacatalogue_metadata_df = DataFrame.from_records(
            DataCatalogueMetaData.objects.get_fares_overall_catalogue().values(
                *DATACATALOGUE_ATTRIBUTE_FIELDS
            )
        )
        if datacatalogue_metadata_df.empty:
            raise EmptyDataFrame()

        datacatalogue_metadata_df.rename(
            columns={"string_nocs": "national_operator_code"}, inplace=True
        )
        datacatalogue_metadata_df.rename(
            columns={"xml_file_name": "filename"}, inplace=True
        )

        merged_fares = merge(
            dataset_df_fares,
            datacatalogue_metadata_df,
            left_on="id",
            right_on="dataset_id",
            how="outer",
        )
        merged_txc = merge(
            dataset_df,
            txc_file_attributes_df,
            left_on="id",
            right_on="dataset_id",
            how="outer",
        )
        merged = pd.concat([merged_fares, merged_txc], ignore_index=True)
    else:
        merged = merge(
            dataset_df,
            txc_file_attributes_df,
            left_on="id",
            right_on="dataset_id",
            how="outer",
        )

    merged["mode"] = "Bus"
    merged = merged.sort_values("id")

    if is_fares_validator_active:
        rename_map = {
            old_name: column_tuple.field_name
            for old_name, column_tuple in FEATURE_FLAG_OVERALL_COLUMN_MAP.items()
        }
        merged = merged[FEATURE_FLAG_OVERALL_COLUMN_MAP.keys()].rename(
            columns=rename_map
        )
    else:
        rename_map = {
            old_name: column_tuple.field_name
            for old_name, column_tuple in OVERALL_COLUMN_MAP.items()
        }
        merged = merged[OVERALL_COLUMN_MAP.keys()].rename(columns=rename_map)

    return merged


def get_overall_data_catalogue_csv() -> str:
    return _get_overall_catalogue_dataframe().to_csv(index=False)
